Задачей проекта являлось построение модели для классификации тестовых комментариев на позитивные и негативные. Исходные данные - таблица, где столбец *text* содержит текст комментария, а *toxic* — целевой признак. Целевая метрика качества *F1* не меньше 0.75

При работе над проектом была проведена лемматизация текстов, очистка от лишних символов, преобразование корпуса в мешок слов и очистка от стоп-слов (лишенных смысловой нагрузки). Данные были разбиты на обучающую и тестовую выборки, на которых были обучаны и протестированы модели `LogisticRegression` и `LGBMClassifier`, показавшие примерно одинаковый результат F1 = 0.76

Использованные библиотеки: `pandas`, `numpy`, `sklearn` (`TfidfVectorizer`), `spacy`, `nltk`, `lightgbm`
